# Disaster Tweet Detection

|                         | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ----------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Dataset                 | For this project, the dataset used is from the [Natural Language Processing with Disaster Tweets Dataset]( https://www.kaggle.com/competitions/nlp-getting-started/data). The dataset used consists of over 7,000 manually classified tweets that cover the categories of disaster and non-disaster tweets. Each tweet is associated with a label of 0 or 1, where 1 indicates that the tweet is a disaster, and 0 indicates that the tweet is not a disaster.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| Problem                 | Twitter, now more commonly known as the X app, is one of the most widely used social media apps today. Twitter has become an important communication channel for people all over the world. Almost all information that happens in real life is now discussed on the app, including emergency situations. The availability of smartphones allows people to announce emergency situations they are experiencing in real time. Therefore, more and more institutions or organizations are interested in monitoring emergency situations through Twitter in a programmed manner and need the program to respond to the situation of a disaster more quickly, especially in emergency situations. This project aims to address this issue by creating a machine learning system that can improve emergency response by automatically identifying tweet sentences that contain disaster information and non-disaster information.                                                                                                                                                                                                                                                                                                                                                                       |
| Machine learning solution | The machine learning solution used in this project involves the use of [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx) as a framework for building and managing machine learning pipelines and [Apache Beam](https://beam.apache.org/) as a pipeline orchestrator. TFX provides components that can be used for data preprocessing, model training, evaluation, and model serving. In this project, TFX components are used in several stages of the machine learning pipeline. The data processing stage uses the ExampleGen component for data ingestion, the StatisticsGen, SchemaGen, and ExampleValidator components for data validation, and the Transform component for data preprocessing. The model development and validation stage uses the Trainer, Tuner, Resolver, and Evaluator components. As for the deployment and model serving stage, the Pusher component is used to move the model that has been created using a docker image that contains the TF-Serving (TensorFlow Serving) model to Railway as a cloud platform for accessing the model via HTTP Request. The entire process is executed using a pipeline orchestrator called Apache Beam. This model is then used in the production environment to classify whether a tweet is a disaster (disaster) or not a disaster (not disaster). |
| Data processing methods       | Data processing involves steps such as cleaning email text, removing special characters, converting letters to lowercase using regular expressions, vectorizing text with the TextVectorization layer from TensorFlow, and word embeddings. In addition, feature selection and handling imbalanced data are also focused by dividing the data into train and validation sets with a percentage of 8:2, and also identifying labels and features from the dataset. The data processing process consists of data ingestion to process data into a certain format to meet standards and perform dataset splitting into train and validation sets, data validation for the data validation process and detecting anomalies in the data, and data preprocessing to prepare the data for use in the training phase.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| Model architecture        | The model architecture used in this project includes the use of deep learning models, which include the Text Vectorization process using the Embedding layer to convert word token representations into numeric vectors with lower dimensions, the Global Average Pooling Layer to reduce the dimensions of the data so that the model is more efficient and prevents overfitting, the Hidden layer consisting of Dense layers to extract more complex features and model non-linear relationships in the data, and since the problem in this project is to solve binary classification in the form of tweet sentences consisting of 2 labels (disaster and not disaster), then the sigmoid activation function is used to solve the problem by generating output that can be interpreted as the probability of the positive class of spam email or vice versa. This model architecture is then integrated into the TFX pipeline by storing it as a function within the trainer module file for structured training and evaluation of the model using the Trainer and Tuner components.                                                                                                                                                                                                                                                              |
| Evaluation metrics         | The evaluation metrics used involve measuring the performance of the model after it has been trained in the Trainer component. These evaluation metrics will calculate the precision and recall values to measure the performance of the classification model, the AUC (Area Under Cover) value to compare the performance of the model in separating the positive and negative classes. Because this project is related to the detection of tweet sentences, the values of false positive (tweets that are incorrectly classified as disaster) and false negative (disaster tweets that are not detected) are of particular concern. In addition, there are also the TruePositives value to count the number of cases where the model successfully classified them as positive (disaster tweet) and the TrueNegatives value to count the number of cases where the model successfully classified them as negative (not disaster tweet). The configuration of these metrics is created using the TFMA (TensorFlow Model Analysis) library as one of the inputs used in the Evaluator component in the TFX pipeline to run the model evaluation process.                                                                                                                                                                                                                                                                                                   |
| Model performance          | The performance of the model was evaluated using the metrics that were mentioned earlier in the section on Evaluation Metrics. The evaluation results showed that out of a total of 1542 tweet examples (eval_set), the False Negative value was 241, meaning that there were 241 positive cases that actually existed (actual positive), but the model incorrectly classified them as negative (predicted negative). The False Positive value was 121, meaning that there were 121 cases that were actually negative (actual negative), but the model incorrectly classified them as positive (predicted positive). The True Negative value was 736, meaning that the model accurately identified 736 that did not actually belong to the positive category and the True Positive value was 444, meaning that the model accurately identified 444 cases that actually belonged to the positive category. It is also known that the results of the model training produced a binary accuracy value of 0.765 or about 76.5%, meaning that the model accurately predicted the target on most of the data with a fairly good accuracy level.                                                                                                                                                                                                                                                                                              |
| Deployment options         | In this project, the deployment option used is to use one of the cloud platforms called [Railway](https://railway.app/). Railway is a cloud Platform-as-a-Service (PaaS) that can be used to deploy an application and supports various programming languages ​​including Python. The trained and created model is then stored in a folder named serving_model through the pipeline orchestration process. First, a docker image is created to hold the TF-Serving model, then the deployment process is carried out using the Railway platform. This model can later be accessed via HTTP Request to perform testing and prediction requests.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| Web app                 | Here is the web app link used to access the serving model: [mlops-disaster-tweets](https://mlops-disaster-tweets-production.up.railway.app/v1/models/tweets-model/metadata)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Monitoring              | For model serving monitoring, a platform called [Prometheus](https://prometheus.io/) is used to view metrics from the running model and [Grafana](https://grafana.com/) as an open-source platform to visualize model metrics captured by Prometheus and display them in the form of an attractive interactive dashboard. There are several metrics that can be displayed by typing the available PromQL commands, in this project the metrics displayed on the Grafana dashboard are Runtime Latency Sum, Request Count, and Request Latency Bucket. Runtime Latency Sum to provide an overview of how fast or slow the model responds to requests, Request Count to show how many requests are received by the model or provide an overview of the workload level or model popularity, and Request Latency Bucket to provide detailed insights into the distribution of the model request response time.                                                                                                                                                                                                                                                                                                                                                                                                          |
