# Disaster Tweet Detection (in Indonesia Language) 

|                         | Deskripsi                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ----------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Dataset                 | Untuk proyek kali ini, dataset yang digunakan berasal dari [Natural Language Processing with Disaster Tweets Dataset](https://www.kaggle.com/competitions/nlp-getting-started/data). Dataset yang digunakan terdiri lebih dari 7.000 tweet yang diklasifikasikan secara manual yang mencangkup kategori tweet berisi kalimat bencana (disaster) dan bukan bencana (not disaster). Setiap tweet dikaitkan dengan label 0 dan 1, dimana angka 1 menunjukkan bahwa tweet tersebut merupakan bencana, dan angka 0 menunjukkan bahwa tweet tersebut bukan bencana.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| Masalah                 | Twitter atau sekarang lebih dikenal dengan aplikasi X merupakan salah satu aplikasi sosial media paling banyak digunakan sekarang ini. Twitter telah menjadi saluran komunikasi penting bagi seluruh masyarakat dunia, hampir semua informasi yang terjadi di kehidupan nyata saat ini pasti dibicarakan juga di aplikasi tersebut, termasuk salah satunya adalah kondisi darurat bencana. Keberadaan ponsel pintar memungkinkan orang untuk mengumumkan keadaan darurat yang mereka alami secara real-time. Oleh karena itu, semakin banyak lembaga atau organisasi yang tertarik untuk memantau keadaan darurat melalui Twitter secara terprogram dan membutuhkan program tersebut untuk merespon keadaan suatu bencana dengan lebih cepat terutama di situasi darurat. Proyek ini bertujuan untuk mengatasi masalah tersebut dengan membuat sebuah sistem machine learning yang mampu meningkatkan respons keadaan darurat dengan secara otomatis mengidentifikasi kalimat tweet yang mengandung informasi bencana dan bukan bencana.                                                                                                                                                                                                                                                                                                                                                                        |
| Solusi machine learning | Solusi machine learning yang digunakan pada proyek ini melibatkan penggunaan [TensorFlow Extended (TFX)](https://www.tensorflow.org/tfx) sebagai kerangka kerja untuk membangun dan mengelola machine learning pipeline dan [Apache Beam](https://beam.apache.org/) sebagai pipeline orcherstator. TFX menyediakan komponen - komponen yang dapat digunakan untuk tahap pra-pemprosesan, pelatihan model, evaluasi, dan penyajian model. Pada proyek ini, komponen TFX digunakan dibeberapa tahapan machine learning pipeline. Tahap pengolahan data menggunakan komponen ExampleGen untuk data ingestion, komponen StatisticsGen, SchemaGen, dan ExampleValidator untuk data validation, komponen Transform untuk data preprocessing. Tahap pengembangan dan validasi model menggunakan komponen Trainer, Tuner, Resolver, dan Evaluator. Sedangkan untuk tahap deployment dan model serving digunakan komponen Pusher untuk memindahkan model yang sudah dibuat dengan menggunakan docker image yang berisi TF-Serving (TensorFlow Serving) model ke Railway sebagai platform cloud untuk mengakses model melalui HTTP Request. Seluruh proses tersebut di jalankan menggunakan sebuah pipeline orchestrator bernama Apache Beam. Model inilah yang nantinya digunakan di production environment untuk mengklasifikasikan apakah sebuah tweet merupakan bencana (disaster) atau bukan bencana (not disaster). |
| Metode pengolahan       | Pengolahan data melibatkan langkah - langkah seperti pembersihan teks email, penghapusan karakter khusus, pengubahan huruf menjadi huruf kecil menggunakan regular expression, vektorisasi teks dengan layer TextVectorization dari TensorFlow, dan word embeddings. Selain itu, pemilihan fitur dan penanganan data yang tidak seimbang (imbalanced data) juga menjadi fokus dengan membagi data menjadi train set dan validation set dengan persentase 8:2 serta dilakukan juga identifikasi label dan fitur dari dataset. Proses pengolahan data terdiri dari data ingestion untuk memproses data ke dalam format tertentu agar sesuai standar dan melakukan pembagian dataset menjadi train set dan validation set, data validation untuk proses validasi data dan mendeteksi anomali pada data, dan data preprocessing untuk mempersiapkan data agar bisa digunakan pada tahap pelatihan.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| Arsitektur model        | Arsitektur model yang digunakan pada proyek ini mencangkup penggunaan model deep learning yang diantaranya terdiri dari proses Text Vectorization menggunakan Embedding layer untuk mengubah representasi token kata menjadi vektor numerik dengan dimensi yang lebih rendah, Global Average Pooling Layer untuk mengurangi dimensi dari data sehingga model lebih efisien dan mencegah overfitting, Hidden layer yang terdiri dari Dense layer untuk mengekstrak fitur - fitur yang lebih kompleks dan memodelkan hubungan non-linear dalam data, serta karena masalah pada proyek ini adalah menyelesaikan klasifikasi biner berupa kalimat tweet yang terdiri dari 2 buah label (disaster dan not disaster) maka digunakan fungsi aktivasi sigmoid untuk menyelesaikan masalah tersebut dengan menghasilkan output yang dapat diinterpretasikan sebagai probabilitas kelas positif email spam atau sebaliknya. Arsitektur model ini kemudian diintegrasikan ke dalam TFX pipeline dengan menyimpannya sebagai fungsi di dalam module file trainer untuk pelatihan dan evaluasi model secara terstruktur menggunakan komponen Trainer dan Tuner.                                                                                                                                                                                                                                                              |
| Metrik evaluasi         | Metrik evaluasi yang digunakan melibatkan pengukuran performa model setelah melalui proses pelatihan pada komponen Trainer. Metrik evaluasi ini akan menghitung nilai precision dan recall untuk menghitung performa model klasifikasi, nilai AUC (Area Under Cover) untuk membandingkan kinerja model dalam memisahkan kelas positif dan negatif. Karena pada proyek kali ini berhubungan dengan deteksi kalimat tweet, nilai dari false positive (tweet yang keliru diklasifikasikan sebagai disaster) dan false negative (disaster tweet yang tidak terdeteksi) menjadi perhatian khusus. Selain itu, terdapat juga nilai TruePositives untuk menghitung jumlah kasus di mana model berhasil mengklasifikasikannya sebagai positif (disaster tweet) dan TrueNegatives untuk menghitung jumlah kasus di mana model berhasil mengklasifikasikannya sebagai negatif (bukan disaster tweet). Konfigurasi metrik tersebut dibuat menggunakan library TFMA (TensorFlow Model Analysis) sebagai salah satu input yang digunakan pada komponen Evaluatorpada TFX pipeline untuk menjalankan proses evaluasi model.                                                                                                                                                                                                                                                                                                   |
| Performa model          | Performa model dievaluasi menggunakan metrik - metrik yang telah disebutkan sebelumnya pada bagian penjelasan Metrik Evaluasi. Hasil evaluasi menunjukkan bahwa dari jumlah sebesar 1542 contoh tweet (eval_set) diketahui nilai False Negative adalah 241, artinya ada 241 kasus positif yang sebenarnya ada (actual positive), tetapi model salah mengklasifikasikannya sebagai negatif (predicted negative). Nilai False Positive adalah 121, artinya terdapat 121 kasus yang sebenarnya negatif (actual negative), tetapi model salah mengklasifikasikannya sebagai positif (predicted positive). Nilai True Negative adalah 736, artinya model secara akurat mengidentifikasi 736 yang sebenarnya tidak termasuk kategori positif serta nilai True Positive adalah 444, artinya model secara akurat mengidentifikasi 444 kasus yang sebenarnya termasuk dalam kategori positif. Diketahui juga hasil dari training model menghasilkan nilai binary accuracy sebesar 0.765 atau sekitar 76.5%, artinya model secara akurat memprediksi target pada sebagian besar data dengan tingkat akurasi yang cukup baik.                                                                                                                                                                                                                                                                                              |
| Opsi deployment         | Pada proyek ini, opsi deployment yang digunakan yaitu menggunakan salah satu platform cloud bernama [Railway](https://railway.app/). Railway merupakan sebuah cloud Platform-as-a-Service (PaaS) yang dapat digunakan untuk men-deploy sebuah aplikasi serta mendukung berbagai jenis bahasa pemprograman termasuk Python. Model yang telah dilatih dan dibuat kemudian disimpan ke dalam sebuah folder bernama serving_model melalui proses pipeline orchestration. Pertama, dibuatkan sebuah docker image untuk menampung model TF-Serving, kemudian dilakukan proses deployment menggunakan platform Railway. Model ini nantinya bisa diakses melalui HTTP Request untuk melakukan pengujian dan prediction request.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| Web app                 | Berikut adalah tautan web app yang digunakan untuk mengakses model serving: [mlops-disaster-tweets](https://mlops-disaster-tweets-production.up.railway.app/v1/models/tweets-model/metadata)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| Monitoring              | Untuk proses monitoring model serving digunakan sebuah platform bernama [Prometheus](https://prometheus.io/) untuk melihat metrik dari model yang dijalankan dan [Grafana](https://grafana.com/) sebagai platform open-source untuk memvisualisasikan metrik model yang ditangkap oleh prometheus dan menampilkannya dalam bentuk dashboard interaktif yang menarik. Terdapat beberapa metrik yang bisa ditampilkan dengan mengetikkan perintah PromQL yang tersedia, pada proyek ini metrik yang ditampilkan pada dashboard Grafana adalah Runtime Latency Sum, Request Count, dan Request Latency Bucket. Runtime Latency Sum untuk memberikan gambaran tentang seberapa cepat atau lambat model merespons permintaan, Request Count untuk menunjukkan seberapa banyak permintaan yang diterima oleh model atau memberikan gambaran tentang tingkat beban kerja atau popularitas model, dan Request Latency Bucket untuk memberikan wawasan rinci tentang distribusi waktu respons permintaan model.                                                                                                                                                                                                                                                                                                                                                                                                          |
